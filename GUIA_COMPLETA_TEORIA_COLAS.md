# ğŸ“š GUÃA COMPLETA: SISTEMA DE TEORÃA DE COLAS M/M/1
## Adonai Store Chatbot - Sistema de AtenciÃ³n Personalizada

---

## ğŸ“ LOCALIZACIÃ“N DE ARCHIVOS

Tu cÃ³digo de TeorÃ­a de Colas estÃ¡ completamente ubicado en la carpeta `chat/`:

```
chat/
â”œâ”€â”€ models.py                          â† Modelo Chat con campos M/M/1
â”œâ”€â”€ views.py                           â† LÃ³gica de atenciÃ³n (lÃ­neas 343-420+)
â”œâ”€â”€ urls.py                            â† Ruta /chat/personalizado/
â”œâ”€â”€ metrics.py                         â† CÃ¡lculos de mÃ©tricas M/M/1 â­
â”œâ”€â”€ management/
â”‚   â””â”€â”€ commands/
â”‚       â””â”€â”€ show_queue_stats.py        â† Comando para ver estadÃ­sticas
â”œâ”€â”€ MM1_README.md                      â† DocumentaciÃ³n tÃ©cnica
â”œâ”€â”€ START_HERE.txt                     â† GuÃ­a de inicio rÃ¡pido
â”œâ”€â”€ TESTING_GUIDE.txt                  â† CÃ³mo probar el sistema
â”œâ”€â”€ DEBUGGING_GUIDE.txt                â† Troubleshooting
â”œâ”€â”€ ADVANCED_GUIDE.txt                 â† Extensiones avanzadas
â””â”€â”€ quick_test.py                      â† Script de prueba automÃ¡tica

static/js/
â””â”€â”€ chat_widget.js                     â† Frontend del botÃ³n "AtenciÃ³n Personalizada"
```

---

## ğŸ¯ Â¿QUÃ‰ ES EL SISTEMA M/M/1?

### DefiniciÃ³n
**M/M/1** es un modelo matemÃ¡tico de **TeorÃ­a de Colas** que simula:
- Un **servidor Ãºnico** atendiendo clientes
- **Llegadas aleatorias** (distribuciÃ³n de Poisson)
- **Tiempos de servicio aleatorios** (distribuciÃ³n exponencial)

### ParÃ¡metros Principales

| ParÃ¡metro | SÃ­mbolo | Significado | Ejemplo |
|-----------|---------|-------------|---------|
| Tasa de llegada | Î» (lambda) | Clientes que llegan por hora | 5 clientes/hora |
| Tasa de servicio | Î¼ (mu) | Clientes atendidos por hora | 10 clientes/hora |
| UtilizaciÃ³n | Ï (rho) | % de tiempo que el servidor estÃ¡ ocupado | 0.5 (50%) |
| Clientes en cola | Lq | Promedio de clientes esperando | 0.33 clientes |
| Tiempo en cola | Wq | Tiempo promedio de espera | 0.067 horas (4 min) |
| Tiempo total | Ws | Tiempo promedio en el sistema | 0.2 horas (12 min) |

### FÃ³rmulas M/M/1

```
Î» = Total de clientes / Horas
Î¼ = 1 / Tiempo promedio de servicio (en horas)
Ï = Î» / Î¼

Lq = ÏÂ² / (1 - Ï)
Wq = Lq / Î»
Ws = 1 / (Î¼ - Î»)
```

**CondiciÃ³n de estabilidad:** Ï < 1 (Si Ï â‰¥ 1, la cola crece infinitamente)

---

## ğŸ”§ COMPONENTES DEL SISTEMA

### 1. **Modelo de Base de Datos** (`models.py`)

```python
class Chat(models.Model):
    usuario = models.ForeignKey(Usuario, on_delete=models.PROTECT)
    
    # Estados del ciclo de vida
    estado = models.CharField(
        choices=[
            ('esperando', 'esperando'),      # En la cola esperando
            ('en_atencion', 'en_atencion'),  # Siendo atendido
            ('finalizado', 'finalizado'),    # AtenciÃ³n completada
            ('cancelado', 'cancelado')       # Cancelado por el usuario
        ]
    )
    
    # Prioridad (1=normal, 2=importante, 3=urgente)
    prioridad = models.IntegerField(default=1)
    
    # Timestamps
    llegada = models.DateTimeField(auto_now_add=True)          # CuÃ¡ndo se solicita
    inicio_servicio = models.DateTimeField(null=True)          # CuÃ¡ndo inicia atenciÃ³n
    fin_servicio = models.DateTimeField(null=True)             # CuÃ¡ndo termina
    duracion_segundos = models.IntegerField(null=True)         # Tiempo total atendido
```

**Modelo complementario:**
```python
class MensajeChat(models.Model):
    chat = models.ForeignKey(Chat, on_delete=models.CASCADE)
    remitente = ('Usuario', 'Bot', 'Empleado')
    contenido = models.TextField()
    fecha_envio = models.DateTimeField(auto_now_add=True)
```

---

### 2. **LÃ³gica de AtenciÃ³n** (`views.py`)

#### FunciÃ³n `asignar_prioridad(mensaje)`
Asigna automÃ¡ticamente prioridad segÃºn palabras clave:

```python
Palabras clave urgentes ("urgente", "reclamo", "problema")    â†’ Prioridad 3
Palabras clave importantes ("pedido", "compra", "orden")       â†’ Prioridad 2
Resto de mensajes                                              â†’ Prioridad 1
```

#### FunciÃ³n `procesar_cola()`
Gestiona quÃ© usuario es atendido:

```
Â¿Hay alguien en 'en_atencion'?
    â”œâ”€ SÃ  â†’ No hacer nada (esperar a que termine)
    â””â”€ NO  â†’ Obtener el primer 'esperando' (ordenado por prioridad y llegada)
             Cambiar estado a 'en_atencion'
             Registrar inicio_servicio
```

#### Endpoint `POST /chat/personalizado/`

**Request:**
```json
{
    "usuario_id": 1,
    "message": "Tengo un problema urgente con mi pedido"
}
```

**Response:**
```json
{
    "ok": true,
    "reply": "ğŸ“‹ Has sido agregado a la cola de atenciÃ³n personalizada.\nHay 2 cliente(s) antes que tÃº. Tu turno llegarÃ¡ pronto.",
    "posicion": 3,
    "estado": "esperando",
    "chat_id": 123,
    "suggested": []
}
```

---

### 3. **CÃ¡lculo de MÃ©tricas** (`metrics.py`)

#### FunciÃ³n `calcular_metricas(horas_atras=24)`

Calcula todas las mÃ©tricas M/M/1 basadas en datos histÃ³ricos:

```python
from chat.metrics import calcular_metricas

metricas = calcular_metricas(horas_atras=24)

# Retorna:
{
    'Î» (Tasa llegada)': 0.5,              # clientes/hora
    'Î¼ (Tasa servicio)': 2.0,             # clientes/hora
    'Ï (UtilizaciÃ³n)': 0.25,              # 25% ocupado
    'Lq (Clientes en cola)': 0.083,       # promedio esperando
    'Wq (Espera promedio)': 0.1,          # horas = 6 minutos
    'Ws (Tiempo total)': 0.6,             # horas = 36 minutos
    'total_chats': 12,                    # chats en las 24h
    'chats_completados': 10,              # chats terminados
    'tiempo_promedio_servicio': 1800.0,   # 30 minutos en segundos
    'estado': 'calculado'
}
```

#### FunciÃ³n `obtener_estadisticas_cola()`

EstadÃ­sticas **en tiempo real** de la cola actual:

```python
from chat.metrics import obtener_estadisticas_cola

stats = obtener_estadisticas_cola()

# Retorna:
{
    'en_cola': 3,                         # Usuarios esperando ahora
    'en_atencion': 1,                     # Usuarios siendo atendidos
    'finalizados': 15,                    # Total completados
    'tiempo_espera_promedio_minutos': 4.5,
    'servidor_disponible': False          # Â¿Hay servidor libre?
}
```

---

## ğŸ“Š FLUJO COMPLETO DE FUNCIONAMIENTO

### Escenario: Usuario solicita "AtenciÃ³n Personalizada"

```
PASO 1: Usuario hace clic en "AtenciÃ³n Personalizada"
â”‚
â”œâ”€ JavaScript (frontend) envÃ­a POST a /chat/personalizado/
â”‚  {usuario_id: 1, message: "Tengo un problema"}
â”‚
PASO 2: Backend recibe y procesa
â”‚
â”œâ”€ chat_personalizado(request):
â”‚  1. Valida usuario
â”‚  2. Asigna prioridad = asignar_prioridad("Tengo un problema") = 3
â”‚  3. Crea Chat(usuario=1, estado='esperando', prioridad=3)
â”‚  4. Guarda MensajeChat(remitente='Usuario', contenido=...)
â”‚
PASO 3: Procesar la cola
â”‚
â”œâ”€ procesar_cola():
â”‚  1. Busca si hay Chat en 'en_atencion'
â”‚  2. Si NO hay: Toma el primer 'esperando' (ordenado por prioridad DESC, llegada ASC)
â”‚     - Cambia estado a 'en_atencion'
â”‚     - Registra inicio_servicio = now()
â”‚  3. Si SÃ hay: No hace nada
â”‚
PASO 4: Determinar respuesta
â”‚
â”œâ”€ Si el chat fue pasado a 'en_atencion':
â”‚  "ğŸ§ Â¡Tu turno ha llegado! Iniciando atenciÃ³n personalizada..."
â”‚  posicion = 0
â”‚
â”œâ”€ Si sigue en 'esperando':
â”‚  Calcula posicion = count(chats esperando ANTES de este)
â”‚  "ğŸ“‹ Has sido agregado a la cola. Hay X cliente(s) antes que tÃº."
â”‚  posicion = X + 1
â”‚
PASO 5: Guardar respuesta del Bot
â”‚
â”œâ”€ MensajeChat(remitente='Bot', contenido=reply)
â”‚
PASO 6: Retornar JSON
â”‚
â””â”€ return JsonResponse({...})
```

### Ejemplo con MÃºltiples Usuarios

```
MOMENTO 1 (10:00)
â”œâ”€ Usuario Juan solicita atenciÃ³n
â”œâ”€ procesar_cola() â†’ No hay en 'en_atencion'
â”œâ”€ Juan â†’ 'en_atencion' (Inicio: 10:00)
â”œâ”€ Respuesta: "Â¡Tu turno ha llegado!"

MOMENTO 2 (10:05)
â”œâ”€ Usuario MarÃ­a solicita atenciÃ³n
â”œâ”€ procesar_cola() â†’ Juan estÃ¡ en 'en_atencion'
â”œâ”€ MarÃ­a â†’ 'esperando' (Prioridad 2)
â”œâ”€ Respuesta: "Hay 0 clientes antes que tÃº. Â¡Eres siguiente!"

MOMENTO 3 (10:07)
â”œâ”€ Usuario Carlos solicita atenciÃ³n (URGENTE - Prioridad 3)
â”œâ”€ procesar_cola() â†’ Juan sigue en 'en_atencion'
â”œâ”€ Carlos â†’ 'esperando' (Prioridad 3 - mÃ¡s urgente que MarÃ­a)
â”œâ”€ Respuesta: "Hay 1 cliente antes que tÃº."

MOMENTO 4 (10:12) 
â”œâ”€ Juan finaliza atenciÃ³n (duracion = 720 segundos = 12 min)
â”œâ”€ procesar_cola() â†’ Â¿QuiÃ©n atender?
â”‚  1. Busca esperando ordenados por prioridad DESC, llegada ASC
â”‚  2. Carlos (Prioridad 3, llegada 10:07) es el primero
â”œâ”€ Carlos â†’ 'en_atencion' (Inicio: 10:12)
â”œâ”€ MarÃ­a sigue esperando

MOMENTO 5 (10:25)
â”œâ”€ Carlos finaliza atenciÃ³n
â”œâ”€ procesar_cola() â†’ MarÃ­a es la Ãºnica esperando
â”œâ”€ MarÃ­a â†’ 'en_atencion' (Inicio: 10:25)
```

---

## ğŸ§ª CÃ“MO PROBAR EL SISTEMA (FUNCIONAL)

### OpciÃ³n 1: Desde el Navegador âœ…

```bash
# 1. Iniciar servidor
python manage.py runserver

# 2. Abrir en navegador
http://127.0.0.1:8000

# 3. Inicia sesiÃ³n
# 4. Haz clic en el chat (esquina inferior derecha)
# 5. Haz clic en "AtenciÃ³n Personalizada"
# 6. RecibirÃ¡s un mensaje indicando tu posiciÃ³n en la cola
```

### OpciÃ³n 2: Desde Django Shell âœ…

```bash
# Acceder a shell
python manage.py shell

# Importar lo necesario
from chat.models import Chat, MensajeChat
from chat.views import chat_personalizado, procesar_cola
from chat.metrics import calcular_metricas, obtener_estadisticas_cola
from usuarios.models import Usuario
from django.utils import timezone
from django.test import RequestFactory
import json

# Test 1: Ver usuarios disponibles
usuarios = Usuario.objects.all()
print(f"Usuarios disponibles: {[u.email for u in usuarios]}")

# Test 2: Crear un "request" simulado
factory = RequestFactory()
usuario = Usuario.objects.first()

request = factory.post('/chat/personalizado/', 
    data=json.dumps({'usuario_id': usuario.id, 'message': 'Tengo un problema urgente'}),
    content_type='application/json'
)

# Test 3: Ejecutar la funciÃ³n
response = chat_personalizado(request)
print(response.content)

# Test 4: Ver la cola actual
chats_esperando = Chat.objects.filter(estado='esperando').order_by('llegada')
print(f"En cola: {chats_esperando.count()} usuarios")

# Test 5: Ver estadÃ­sticas
stats = obtener_estadisticas_cola()
print(f"EstadÃ­sticas: {stats}")

# Test 6: Ver mÃ©tricas M/M/1
metricas = calcular_metricas(horas_atras=24)
print(f"MÃ©tricas: {metricas}")
```

### OpciÃ³n 3: Desde Terminal (Comando) âœ…

```bash
# Ver estadÃ­sticas actuales
python manage.py show_queue_stats

# Salida esperada:
# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘      ESTADÃSTICAS DE COLA M/M/1                â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 
# Tasa de llegada (Î»):        0.5000
# Tasa de servicio (Î¼):       2.0000
# UtilizaciÃ³n (Ï):            0.2500
# Clientes en cola (Lq):      0.0833
# Tiempo en cola (Wq):        0.1000 horas
# Tiempo total (Ws):          0.6000 horas
# ...

# Con opciones
python manage.py show_queue_stats --horas 48
python manage.py show_queue_stats --cola
```

### OpciÃ³n 4: Script de Prueba AutomÃ¡tica âœ…

```bash
# Ejecutar pruebas automÃ¡ticas
python manage.py shell < chat/quick_test.py

# Te mostrarÃ¡ 10 pruebas automÃ¡ticas
```

---

## ğŸ“ˆ EJEMPLO REAL: ANÃLISIS DE DATOS

Supongamos que en las Ãºltimas 24 horas tienes estos datos:

| ID | Usuario | Llegada | Inicio | Fin | DuraciÃ³n |
|----|---------|---------|--------|-----|----------|
| 1 | juan | 10:00 | 10:00 | 10:15 | 900s |
| 2 | maria | 10:05 | 10:15 | 10:30 | 900s |
| 3 | carlos | 10:10 | 10:30 | 10:42 | 720s |
| ... | ... | ... | ... | ... | ... |
| 24 | ana | 18:00 | 18:00 | 18:05 | 300s |

**CÃ¡lculos:**
```
Total usuarios: 24
Usuarios completados: 22
Horas: 24

Î» = 24 / 24 = 1 cliente/hora
Î¼ = 1 / (13500/22) â‰ˆ 5.87 clientes/hora
Ï = 1 / 5.87 â‰ˆ 0.17 (servidor 17% ocupado)

Lq = 0.17Â² / (1 - 0.17) â‰ˆ 0.0035 clientes
Wq = 0.0035 / 1 â‰ˆ 0.0035 horas â‰ˆ 12.6 segundos
Ws = 1 / (5.87 - 1) â‰ˆ 0.205 horas â‰ˆ 12.3 minutos
```

**InterpretaciÃ³n:**
- El servidor estÃ¡ muy poco utilizado (17%)
- Los usuarios esperan en promedio 12.6 segundos
- El tiempo total en el sistema es 12.3 minutos
- El sistema es muy eficiente

---

## ğŸ” DEBUGGING: PROBLEMAS Y SOLUCIONES

### âŒ El botÃ³n "AtenciÃ³n Personalizada" no aparece

**SoluciÃ³n:**
```bash
# 1. Verificar que el archivo chat_widget.js estÃ¡ actualizado
grep -n "AtenciÃ³n Personalizada" static/js/chat_widget.js

# 2. Si no aparece, revisar en la consola de navegador (F12)
# 3. Verificar que las URLs estÃ©n cargadas correctamente
```

### âŒ El usuario no ve su posiciÃ³n en la cola

**SoluciÃ³n:**
```python
# En Django shell:
from chat.models import Chat
from django.db.models import Count

# Ver todos los chats esperando
esperando = Chat.objects.filter(estado='esperando').order_by('llegada')
print(f"Usuarios esperando: {esperando.count()}")

# Ver orden de la cola
for i, chat in enumerate(esperando, 1):
    print(f"{i}. {chat.usuario.email} (prioridad {chat.prioridad})")
```

### âŒ Las mÃ©tricas son incorrectas o muestran "sin_datos"

**SoluciÃ³n:**
```python
# En Django shell:
from chat.models import Chat
from django.utils import timezone
from datetime import timedelta

# Verificar que hay chats completados
tiempo_limite = timezone.now() - timedelta(hours=24)
completados = Chat.objects.filter(
    estado='finalizado',
    duracion_segundos__isnull=False,
    llegada__gte=tiempo_limite
)
print(f"Chats completados en 24h: {completados.count()}")

# Si es 0, crear chats de prueba
from usuarios.models import Usuario
usuario = Usuario.objects.first()
chat = Chat.objects.create(usuario=usuario, estado='finalizado', duracion_segundos=600)
```

### âŒ El comando `show_queue_stats` no funciona

**SoluciÃ³n:**
```bash
# Verificar que el archivo existe
ls -la chat/management/commands/show_queue_stats.py

# Si no existe, crear el archivo o crear la carpeta
mkdir -p chat/management/commands
touch chat/management/commands/__init__.py

# Intentar nuevamente
python manage.py show_queue_stats
```

---

## ğŸ’¡ CASOS DE USO Y EJEMPLOS

### Caso 1: Tienda con Mucho TrÃ¡fico

```
Escenario: Black Friday - 100 clientes por hora

Î» = 100 clientes/hora
Î¼ = 10 clientes/hora (pueden atender 1 cada 6 minutos)
Ï = 100 / 10 = 10 âŒ INESTABLE (Ï > 1)

SoluciÃ³n: Aumentar Î¼ a 200+ clientes/hora
- Agregar mÃ¡s servidores (cambiar a M/M/2, M/M/3, etc.)
- Mejorar tiempo de servicio
```

### Caso 2: Tienda PequeÃ±a con Bajo TrÃ¡fico

```
Escenario: Tienda pequeÃ±a - 2 clientes por hora

Î» = 2 clientes/hora
Î¼ = 6 clientes/hora
Ï = 2/6 â‰ˆ 0.33
Lq = 0.33Â² / (1 - 0.33) â‰ˆ 0.16 clientes
Wq = 0.16 / 2 â‰ˆ 0.08 horas â‰ˆ 4.8 minutos

InterpretaciÃ³n: Sistema muy eficiente, pocas colas
```

---

## ğŸ“¦ ESTRUCTURA RESUMIDA

```
chat/
â”‚
â”œâ”€ DATABASE LAYER
â”‚  â””â”€ models.py (Chat, MensajeChat)
â”‚
â”œâ”€ BUSINESS LOGIC
â”‚  â”œâ”€ views.py (asignar_prioridad, procesar_cola, chat_personalizado)
â”‚  â””â”€ metrics.py (calcular_metricas, obtener_estadisticas_cola)
â”‚
â”œâ”€ API ENDPOINTS
â”‚  â””â”€ urls.py (/chat/personalizado/)
â”‚
â”œâ”€ FRONTEND
â”‚  â””â”€ templates/chat/ (plantillas)
â”‚
â”œâ”€ COMMANDS
â”‚  â””â”€ management/commands/show_queue_stats.py
â”‚
â””â”€ DOCUMENTATION
   â”œâ”€ MM1_README.md (esta guÃ­a)
   â”œâ”€ START_HERE.txt
   â”œâ”€ TESTING_GUIDE.txt
   â”œâ”€ DEBUGGING_GUIDE.txt
   â”œâ”€ ADVANCED_GUIDE.txt
   â””â”€ quick_test.py
```

---

## âœ… CHECKLIST: SISTEMA FUNCIONAL

- [x] Modelo Chat creado con campos necesarios
- [x] FunciÃ³n asignar_prioridad() implementada
- [x] FunciÃ³n procesar_cola() implementada
- [x] Endpoint /chat/personalizado/ funcional
- [x] MÃ©tricas M/M/1 calculadas correctamente
- [x] BotÃ³n "AtenciÃ³n Personalizada" en frontend
- [x] Comando show_queue_stats implementado
- [x] DocumentaciÃ³n completa
- [x] Sistema listo para producciÃ³n

---

## ğŸ“ RECURSOS ADICIONALES

### TeorÃ­a de Colas M/M/1
- Libro: "Operations Research: An Introduction" de Hamdy Taha
- TeorÃ­a: https://en.wikipedia.org/wiki/M/M/1_queue
- FÃ³rmulas: https://www.britannica.com/technology/queue

### ImplementaciÃ³n en Django
- Django Models: https://docs.djangoproject.com/en/stable/topics/db/models/
- Django Views: https://docs.djangoproject.com/en/stable/topics/http/views/
- Django Shell: https://docs.djangoproject.com/en/stable/ref/django-admin/#shell

### Archivos de Referencia en el Proyecto
- `chat/MM1_README.md` - DocumentaciÃ³n tÃ©cnica
- `chat/TESTING_GUIDE.txt` - GuÃ­a de pruebas
- `chat/ADVANCED_GUIDE.txt` - Extensiones avanzadas
- `chat/quick_test.py` - Script de prueba

---

## ğŸš€ PRÃ“XIMOS PASOS

1. **Prueba en navegador:**
   ```bash
   python manage.py runserver
   # Abre http://127.0.0.1:8000 e inicia sesiÃ³n
   ```

2. **Verifica las mÃ©tricas:**
   ```bash
   python manage.py show_queue_stats
   ```

3. **Integra con tu dashboard (opcional):**
   - AgregaaÃºn template HTML para ver estadÃ­sticas
   - Agrega grÃ¡ficos con Chart.js
   - Crea un endpoint de API para mÃ©tricas en JSON

4. **Extiende el sistema (opcional):**
   - Ver `ADVANCED_GUIDE.txt` para integraciÃ³n con Gemini AI
   - Agregar WebSockets para notificaciones en tiempo real
   - Crear panel administrativo visual

---

**Â¡Tu sistema de TeorÃ­a de Colas M/M/1 estÃ¡ completamente funcional y listo para usar!** ğŸ‰

Para cualquier duda o problema, consulta los archivos de documentaciÃ³n en `chat/` o contacta al equipo de desarrollo.

Ãšltima actualizaciÃ³n: 13 de Noviembre de 2024
